from typing import TypedDict, Annotated, List
from langchain_core.messages import BaseMessage
import operator


class AgentState(TypedDict):
    """
    Определяет структуру состояния для графа голосового ассистента.

    Это состояние отслеживает как историю диалога для LLM, так и текущий
    контекст работы ассистента (файлы, аудио, текст для озвучки).
    """

    # --- Диалоговая часть ---

    # `messages` будет накапливать историю сообщений.
    # Annotated[..., operator.add] говорит графу "не заменяй, а добавляй".
    # Каждый раз, когда узел вернет ключ "messages", новый список сообщений
    # будет добавлен к старому.
    messages: Annotated[List[BaseMessage], operator.add]

    # --- Входные данные от пользователя ---

    # Путь к последнему записанному аудиофайлу.
    # Это значение будет перезаписываться при каждой новой записи.
    audio_filepath: str

    # Расшифрованный текст из последнего аудиофайла.
    # Также перезаписывается.
    transcribed_message: str

    # --- Контекст работы ассистента ---

    # Текущий проект или рабочая область.
    curr_project: str

    # Текущая директория, в которой работает ассистент.
    curr_dir: str

    # Текущий файл, с которым работает ассистент.
    curr_file: str

    # --- Выходные данные для пользователя ---

    # Текст, который ассистент должен произнести.
    # Генерируется LLM или другим инструментом.
    text_to_pronounce: str

    # Путь к сгенерированному аудиофайлу, который нужно воспроизвести.
    audio_to_pronounce: str